# Vikidia vs Wikipedia
Parallel datasets on 5 languages for binary language complexity

## Purpose

This dataset was collected to perform simplified language complexity task (Vikidia = easy, Wikipedia=normal)

## Process of collection
A number of headings were taken from english Vikidia, and articles from (english) Wikipedia were taken from these headings. On these texts a model that trained for NER task was launched. In the column "entity" was put most common entity in corresponding text.

The English file has been translated into other languages.
